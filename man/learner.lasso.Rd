% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/learner.lasso.R
\name{learner.lasso}
\alias{learner.lasso}
\title{Basic glmnet learner}
\usage{
learner.lasso(data = data_train_numeric_clean_imputed, lasso = FALSE,
  boruta = FALSE)
}
\arguments{
\item{data}{Input data which is default set to the numeric, imputed and cleaned training dataset}

\item{lasso}{Boolean flag that shrinks data to the features of \code{feature.lasso()} stored in
the variable \code{features_lasso}}

\item{boruta}{Boolean flag that shrinks data to the features of \code{boruta.lasso()} stored in
the variable \code{features_boruta}}
}
\value{
0 as error output if both flags are set to true
}
\description{
Parallel tuning function using glmnet that is either based on glmnet, boruta or the whole dataset.
}
\details{
The default execution uses the whole training dataset. By setting either the \code{lasso} or
\code{boruta} parameter to true the number of features is reduced according to the results of
the feature selection. The glmnet learner is wrapper in a Filter wrapper that uses chi squared
as feature selection method. The result is three times cross validated
at maximum 2000 experiments using irace as a control structure.
}
\examples{
KaggleHouse:::learner.lasso(lasso=TRUE)

}

